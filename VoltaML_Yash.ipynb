{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Importing Libraries\n",
        "import os \n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization,Flatten\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Model"
      ],
      "metadata": {
        "id": "F6IEPaf3K_9V"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir('/content/drive/MyDrive/ML Club NITS/Datasets/natural_images')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuEVuJJmgiNO",
        "outputId": "42b2834b-6bf3-4899-ff74-593e3e71606a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['person', 'airplane', 'motorbike', 'fruit', 'flower', 'car', 'cat', 'dog']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def img_read(folder):\n",
        "    imgg=[] \n",
        "    labels = []\n",
        "    classes = ['person', 'airplane', 'motorbike', 'fruit', 'flower', 'car', 'cat', 'dog']\n",
        "    for i in classes:\n",
        "        for filename in tqdm(os.listdir(os.path.join(folder , i))):\n",
        "            img = cv2.imread(os.path.join(os.path.join(folder,i) , filename)) #Reading the image file from the base directory\n",
        "            img = cv2.resize(img , (150 , 150)) # Resizing the images to a matrix of (150,150)\n",
        "            imgg.append(img) #Storing the Image one by one in an empty list\n",
        "            labels.append(i) #Storing the labels of the image one by one in an empty list \n",
        "    return imgg , labels"
      ],
      "metadata": {
        "id": "xc7Mtn99hS8-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img , label = img_read('/content/drive/MyDrive/ML Club NITS/Datasets/natural_images')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiYtg-3cika0",
        "outputId": "78d83d95-ac12-4d98-add6-f5a5158801ae"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 986/986 [00:18<00:00, 53.24it/s] \n",
            "100%|██████████| 727/727 [00:08<00:00, 89.70it/s] \n",
            "100%|██████████| 788/788 [00:10<00:00, 74.54it/s] \n",
            "100%|██████████| 1000/1000 [00:11<00:00, 85.71it/s]\n",
            "100%|██████████| 843/843 [00:13<00:00, 62.63it/s] \n",
            "100%|██████████| 968/968 [00:10<00:00, 90.91it/s] \n",
            "100%|██████████| 885/885 [00:12<00:00, 70.18it/s] \n",
            "100%|██████████| 702/702 [00:08<00:00, 83.69it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating data generator training and validation dataset\n",
        "dir = '/content/drive/MyDrive/ML Club NITS/Datasets/natural_images'\n",
        "data_gen = ImageDataGenerator(rescale = 1./255,\n",
        "                              horizontal_flip=True,\n",
        "                              brightness_range=[0.4,1.5],# values less then 1 darken the image and greater than 1 brighten.\n",
        "                              validation_split=0.2)\n",
        "train_datagen = data_gen.flow_from_directory(dir,\n",
        "                                         batch_size = 64,\n",
        "                                         class_mode = \"categorical\",\n",
        "                                         target_size = (150,150),\n",
        "                                         subset = \"training\")\n",
        "val_datagen = data_gen.flow_from_directory(\n",
        "    dir,\n",
        "    batch_size =64 ,\n",
        "    class_mode = \"categorical\",\n",
        "    target_size = (150,150),\n",
        "    subset = \"validation\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy-ya-R0Ssq6",
        "outputId": "6728cb90-7cb9-450e-d0df-bb9b2d46c2e5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5522 images belonging to 8 classes.\n",
            "Found 1377 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Construction \n",
        "inputs = tf.keras.Input(shape=(150,150,3))\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same',)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same',)(x)\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "x = Dropout(0.2)(x)\n",
        "x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(16,activation='relu')(x)\n",
        "output = Dense(8, activation='softmax')(x)\n",
        "model = Model(inputs, output)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mmNDmE3j4Ibu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Callbacks\n",
        "EP = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5\n",
        ")\n",
        "MCP = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = './weights' ,\n",
        "    monitor='accuracy' , \n",
        "    save_best_only=True\n",
        ")"
      ],
      "metadata": {
        "id": "jvznnV8xBJS5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nz5PmkmCccJ",
        "outputId": "7f7b7094-cdaa-48ca-b4b1-354eb93c685d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 150, 150, 64)      1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 150, 150, 32)      18464     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 75, 75, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 75, 75, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 75, 75, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 37, 37, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 37, 37, 32)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 37, 37, 16)        4624      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 21904)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 16)                350480    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 8)                 136       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 384,744\n",
            "Trainable params: 384,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_datagen,\n",
        "    batch_size=128,\n",
        "    epochs=5,\n",
        "    #steps_per_epoch=100,\n",
        "    verbose=1,\n",
        "    validation_data=val_datagen,\n",
        "    callbacks=[EP,MCP]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhFTVeIOGD8P",
        "outputId": "237c5ff7-c4c0-4811-819a-6b171e91e1fe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "87/87 [==============================] - ETA: 0s - loss: 1.2737 - accuracy: 0.5522"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r87/87 [==============================] - 40s 346ms/step - loss: 1.2737 - accuracy: 0.5522 - val_loss: 1.0926 - val_accuracy: 0.6652\n",
            "Epoch 2/5\n",
            "87/87 [==============================] - ETA: 0s - loss: 0.6563 - accuracy: 0.7807"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r87/87 [==============================] - 28s 327ms/step - loss: 0.6563 - accuracy: 0.7807 - val_loss: 0.5617 - val_accuracy: 0.7996\n",
            "Epoch 3/5\n",
            "87/87 [==============================] - ETA: 0s - loss: 0.4276 - accuracy: 0.8519"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r87/87 [==============================] - 28s 325ms/step - loss: 0.4276 - accuracy: 0.8519 - val_loss: 0.4869 - val_accuracy: 0.8301\n",
            "Epoch 4/5\n",
            "87/87 [==============================] - ETA: 0s - loss: 0.3539 - accuracy: 0.8740"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r87/87 [==============================] - 28s 325ms/step - loss: 0.3539 - accuracy: 0.8740 - val_loss: 0.4060 - val_accuracy: 0.8642\n",
            "Epoch 5/5\n",
            "87/87 [==============================] - ETA: 0s - loss: 0.3171 - accuracy: 0.8874"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r87/87 [==============================] - 28s 325ms/step - loss: 0.3171 - accuracy: 0.8874 - val_loss: 0.4168 - val_accuracy: 0.8577\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\")\n",
        "print('model saved')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imR5qDcuGQfH",
        "outputId": "28b3779e-09c4-4d45-80ff-2d69da16bd86"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model saved\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K_LgVYNQO-Cz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}